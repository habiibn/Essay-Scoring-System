{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SUjaSrAtryJ",
        "outputId": "dc026a82-1b00-4994-ced4-9c308781fde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n"
          ]
        }
      ],
      "source": [
        "! pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv17hzafuIc3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d9S-4JJuV-B"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = \"../content/\"\n",
        "GLOVE_DIR = './glove.6B/'\n",
        "SAVE_DIR = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EirNAdNduhud",
        "outputId": "08a84bb8-50fe-4f61-b166-34c9fbfea710"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12971</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12976 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  Dear local newspaper, I think effects computer...   \n",
              "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "...         ...        ...                                                ...   \n",
              "12971     21626          8   In most stories mothers and daughters are eit...   \n",
              "12972     21628          8   I never understood the meaning laughter is th...   \n",
              "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "12974     21630          8                                 Trippin' on fen...   \n",
              "12975     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "       domain1_score  \n",
              "0                  8  \n",
              "1                  9  \n",
              "2                  7  \n",
              "3                 10  \n",
              "4                  8  \n",
              "...              ...  \n",
              "12971             35  \n",
              "12972             32  \n",
              "12973             40  \n",
              "12974             40  \n",
              "12975             40  \n",
              "\n",
              "[12976 rows x 4 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
        "y = X['domain1_score']\n",
        "X = X.dropna(axis=1)\n",
        "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym2cYTOovKGX"
      },
      "outputs": [],
      "source": [
        "min_scores = np.array([-1, 2, 1, 0, 0, 0, 0, 0, 0])\n",
        "max_scores = np.array([-1, 12, 6, 3, 3, 4, 4, 30, 60])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oK7QoHjQvNOI",
        "outputId": "6dc62906-1287-4c68-baed-a8e8a919234d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e083014-e087-4257-afd7-750367db839c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12971</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>35</td>\n",
              "      <td>58.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>32</td>\n",
              "      <td>53.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12976 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e083014-e087-4257-afd7-750367db839c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e083014-e087-4257-afd7-750367db839c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e083014-e087-4257-afd7-750367db839c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  Dear local newspaper, I think effects computer...   \n",
              "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "...         ...        ...                                                ...   \n",
              "12971     21626          8   In most stories mothers and daughters are eit...   \n",
              "12972     21628          8   I never understood the meaning laughter is th...   \n",
              "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "12974     21630          8                                 Trippin' on fen...   \n",
              "12975     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "       domain1_score      score  \n",
              "0                  8  60.000000  \n",
              "1                  9  70.000000  \n",
              "2                  7  50.000000  \n",
              "3                 10  80.000000  \n",
              "4                  8  60.000000  \n",
              "...              ...        ...  \n",
              "12971             35  58.333333  \n",
              "12972             32  53.333333  \n",
              "12973             40  66.666667  \n",
              "12974             40  66.666667  \n",
              "12975             40  66.666667  \n",
              "\n",
              "[12976 rows x 5 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "old_min = min_scores[X['essay_set']]\n",
        "old_max = max_scores[X['essay_set']]\n",
        "old_range = old_max - old_min\n",
        "new_min = 0\n",
        "new_max = 100\n",
        "new_range = (new_max - new_min)  \n",
        "X['score'] = (((X['domain1_score'] - old_min) * new_range) / old_range) + new_min\n",
        "\n",
        "y = np.round(X['score'])\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEULgzV_vW1P",
        "outputId": "4bb56f34-c7db-44aa-f635-a4b94dd88c0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        60.0\n",
              "1        70.0\n",
              "2        50.0\n",
              "3        80.0\n",
              "4        60.0\n",
              "         ... \n",
              "12971    58.0\n",
              "12972    53.0\n",
              "12973    67.0\n",
              "12974    67.0\n",
              "12975    67.0\n",
              "Name: score, Length: 12976, dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyLR33CYvaBv",
        "outputId": "19dc49d2-b167-401b-b4e9-2ec955d22007"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def essays_to_wordlist(essay_v, remove_stopwords):\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)\n",
        "\n",
        "def essays_to_sentences(essay_v, remove_stopwords):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(essays_to_wordlist(raw_sentence, remove_stopwords))\n",
        "    return sentences\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    # index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec, model[word])       \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cJNB6j4wIDh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, model_from_config\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def getmodel():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(200, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 200], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-ntpI7Ywbz7"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for essay in X['essay']:\n",
        "    corpus.append(essays_to_wordlist(essay, True))\n",
        "\n",
        "embedding_dict={}\n",
        "with open('/content/glove.6B.200d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word] = vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuAW1_J522DL",
        "outputId": "fdef42f9-bc5c-4376-e329-6e18aa68fc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 10s 21ms/step - loss: 2672.6807 - mae: 46.6787\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1929.2158 - mae: 38.4824\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1415.7772 - mae: 31.8554\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1035.6649 - mae: 26.5177\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 4s 27ms/step - loss: 773.3890 - mae: 22.6583\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 4s 24ms/step - loss: 639.0764 - mae: 20.3728\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 606.1488 - mae: 19.6495\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 591.7869 - mae: 19.3756\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 541.6224 - mae: 18.4797\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 518.5538 - mae: 17.9659\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 502.8181 - mae: 17.6346\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 491.8281 - mae: 17.4876\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 480.3748 - mae: 17.2187\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 472.2377 - mae: 17.0417\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 462.8556 - mae: 16.8700\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 451.9373 - mae: 16.7328\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 447.5579 - mae: 16.6527\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 441.8518 - mae: 16.4716\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 440.0437 - mae: 16.4464\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.3495 - mae: 16.4200\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 423.5803 - mae: 16.0630\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 428.9897 - mae: 16.2307\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 428.5183 - mae: 16.1881\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 413.8267 - mae: 15.9080\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 415.8214 - mae: 15.9099\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 408.7957 - mae: 15.8573\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 404.0211 - mae: 15.7090\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 401.1947 - mae: 15.6329\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 398.3006 - mae: 15.5987\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 395.1987 - mae: 15.5213\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 388.0929 - mae: 15.3795\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 388.3135 - mae: 15.4429\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 384.1538 - mae: 15.3175\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 382.8714 - mae: 15.3271\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 378.5131 - mae: 15.2597\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 373.2366 - mae: 15.1232\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 373.8669 - mae: 15.1247\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 378.3767 - mae: 15.2157\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.2249 - mae: 14.9876\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 366.6355 - mae: 14.9546\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 370.9138 - mae: 15.1037\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 365.9333 - mae: 15.0548\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 361.1456 - mae: 14.9328\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 359.6897 - mae: 14.8688\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 18ms/step - loss: 358.3121 - mae: 14.8467\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 357.7191 - mae: 14.8781\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 356.9964 - mae: 14.7814\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 359.3987 - mae: 14.8715\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 18ms/step - loss: 348.7907 - mae: 14.6272\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 348.3498 - mae: 14.6123\n",
            "82/82 [==============================] - 1s 3ms/step\n",
            "Kappa Score: 0.6611245245641602\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 20ms/step - loss: 2698.8730 - mae: 46.9672\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1947.5006 - mae: 38.7798\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1431.9404 - mae: 32.1041\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1043.6860 - mae: 26.7190\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 787.3843 - mae: 22.9289\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 652.2634 - mae: 20.5457\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 601.3517 - mae: 19.5741\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 578.0474 - mae: 19.1314\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 530.3112 - mae: 18.2105\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 501.6831 - mae: 17.6662\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 492.0779 - mae: 17.4673\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 479.4413 - mae: 17.1848\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 477.8416 - mae: 17.2105\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 464.4239 - mae: 16.9042\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 460.4185 - mae: 16.8625\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 452.2856 - mae: 16.6737\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 449.8396 - mae: 16.5638\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.7646 - mae: 16.4144\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 438.1497 - mae: 16.3954\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 424.9590 - mae: 16.1295\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 424.8655 - mae: 16.1489\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 427.3833 - mae: 16.1670\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 417.8435 - mae: 15.8915\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 416.3316 - mae: 15.9045\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 414.6293 - mae: 15.9366\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 408.2706 - mae: 15.7787\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 406.9213 - mae: 15.7323\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 404.7202 - mae: 15.7332\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 396.6794 - mae: 15.5845\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 393.1125 - mae: 15.5091\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 392.2645 - mae: 15.4906\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 390.8534 - mae: 15.4971\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 385.5491 - mae: 15.3249\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 386.0524 - mae: 15.3170\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 374.8188 - mae: 15.0989\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 377.4406 - mae: 15.2110\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 371.9278 - mae: 15.0794\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 376.5686 - mae: 15.1425\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 371.2856 - mae: 15.0945\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 369.3568 - mae: 15.0270\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.9240 - mae: 14.8958\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 364.7927 - mae: 14.9280\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 365.4706 - mae: 14.9131\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 358.6590 - mae: 14.8016\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 352.0010 - mae: 14.6922\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 350.8768 - mae: 14.6234\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 18ms/step - loss: 353.9607 - mae: 14.7276\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 347.2097 - mae: 14.5257\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 355.3467 - mae: 14.7894\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 349.5078 - mae: 14.5386\n",
            "82/82 [==============================] - 1s 3ms/step\n",
            "Kappa Score: 0.6356328232747533\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 19ms/step - loss: 2762.7317 - mae: 47.6019\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 2006.8718 - mae: 39.4807\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1480.5403 - mae: 32.7429\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1079.7596 - mae: 27.2171\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 4s 25ms/step - loss: 798.4005 - mae: 23.0785\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 646.8834 - mae: 20.5725\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 598.0273 - mae: 19.5360\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 590.4889 - mae: 19.3931\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 542.8903 - mae: 18.4722\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 519.0454 - mae: 17.9645\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 499.5690 - mae: 17.6239\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 489.8231 - mae: 17.3969\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 479.2430 - mae: 17.1474\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 474.7262 - mae: 17.0524\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 468.4376 - mae: 16.9118\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 457.0974 - mae: 16.7196\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 452.2019 - mae: 16.6320\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.6208 - mae: 16.3973\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.8860 - mae: 16.4295\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 437.2573 - mae: 16.4194\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 430.7420 - mae: 16.2176\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 426.6248 - mae: 16.1316\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 425.2744 - mae: 16.0876\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 418.0862 - mae: 16.0618\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 419.9966 - mae: 15.9637\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 420.1334 - mae: 16.0276\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 410.6443 - mae: 15.7987\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 401.6038 - mae: 15.6609\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 409.0462 - mae: 15.7646\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 404.6292 - mae: 15.7128\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 394.7194 - mae: 15.4799\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 392.8404 - mae: 15.4718\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 388.6353 - mae: 15.4493\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 379.2338 - mae: 15.1835\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 375.3712 - mae: 15.1098\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 375.4501 - mae: 15.1530\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.9607 - mae: 15.0030\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 375.8416 - mae: 15.1274\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 373.0954 - mae: 15.0722\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 373.4862 - mae: 15.0768\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 362.0414 - mae: 14.8420\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 366.0002 - mae: 14.9371\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.2393 - mae: 14.9680\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 359.3964 - mae: 14.7862\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 356.8734 - mae: 14.7637\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 357.4982 - mae: 14.7835\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 360.8893 - mae: 14.8468\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 353.1685 - mae: 14.6434\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 349.8675 - mae: 14.6074\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 339.1474 - mae: 14.4373\n",
            "82/82 [==============================] - 1s 3ms/step\n",
            "Kappa Score: 0.6527565637462656\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 21ms/step - loss: 2671.7153 - mae: 46.6890\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1931.3606 - mae: 38.5507\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1423.0897 - mae: 31.9175\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1032.5123 - mae: 26.5156\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 775.5212 - mae: 22.7077\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 638.3588 - mae: 20.4170\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 605.1861 - mae: 19.6494\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 587.9741 - mae: 19.3182\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 546.6511 - mae: 18.5412\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 513.2340 - mae: 17.8956\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 503.7606 - mae: 17.6556\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 488.4251 - mae: 17.4054\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 488.1822 - mae: 17.3647\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 474.8081 - mae: 17.1455\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 469.1220 - mae: 17.0472\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 457.7892 - mae: 16.8341\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 457.9835 - mae: 16.7889\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 446.8854 - mae: 16.6213\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 439.2736 - mae: 16.4325\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 4s 23ms/step - loss: 435.1624 - mae: 16.3760\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 426.7927 - mae: 16.1613\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 426.3866 - mae: 16.1461\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 422.2325 - mae: 16.0835\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 420.3429 - mae: 15.9943\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 414.3321 - mae: 15.8362\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 409.6817 - mae: 15.8707\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 413.5793 - mae: 15.8460\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 402.1431 - mae: 15.7092\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 401.2199 - mae: 15.5848\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 394.8443 - mae: 15.4885\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 391.3001 - mae: 15.5313\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 389.7347 - mae: 15.4924\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 384.1045 - mae: 15.3406\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 380.1281 - mae: 15.1921\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 385.7139 - mae: 15.2668\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 372.3704 - mae: 15.0881\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 379.3423 - mae: 15.1937\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 371.9112 - mae: 15.0840\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 373.6100 - mae: 15.1412\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 372.1598 - mae: 15.0150\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 362.9885 - mae: 14.9172\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 364.5545 - mae: 14.9649\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 366.6730 - mae: 14.9251\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 364.5608 - mae: 14.9267\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 353.0946 - mae: 14.6589\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 354.0661 - mae: 14.6919\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 348.2056 - mae: 14.6376\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 356.4151 - mae: 14.7808\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 357.7351 - mae: 14.6854\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 348.2468 - mae: 14.6198\n",
            "82/82 [==============================] - 1s 4ms/step\n",
            "Kappa Score: 0.6522686709462799\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 21ms/step - loss: 2707.2300 - mae: 47.0729\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1966.4402 - mae: 38.9944\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1444.7643 - mae: 32.2978\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1054.2739 - mae: 26.8590\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 785.2654 - mae: 22.8549\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 643.4830 - mae: 20.5031\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 606.4999 - mae: 19.6621\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 601.8312 - mae: 19.5152\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 578.7626 - mae: 19.1554\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 520.3866 - mae: 18.0215\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 504.6905 - mae: 17.7269\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 492.5694 - mae: 17.4091\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 483.2235 - mae: 17.2588\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 472.2931 - mae: 17.0683\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 459.6768 - mae: 16.8712\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 461.2121 - mae: 16.8866\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 442.1555 - mae: 16.5228\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 4s 23ms/step - loss: 447.5595 - mae: 16.6145\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 436.4877 - mae: 16.3366\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 434.2061 - mae: 16.3242\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 429.8312 - mae: 16.2778\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 427.3695 - mae: 16.1927\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 422.2131 - mae: 16.0730\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 4s 28ms/step - loss: 413.4859 - mae: 15.9206\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 411.7534 - mae: 15.9126\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 410.3990 - mae: 15.8260\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 408.9684 - mae: 15.8136\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 401.2662 - mae: 15.6811\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 399.6621 - mae: 15.5958\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 392.6707 - mae: 15.4854\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 385.6630 - mae: 15.3763\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 381.5781 - mae: 15.2885\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 382.4182 - mae: 15.3359\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 378.8458 - mae: 15.2225\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 377.9791 - mae: 15.2118\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 379.2138 - mae: 15.1951\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 371.5058 - mae: 15.0909\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 371.7595 - mae: 15.0664\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 373.4474 - mae: 15.1056\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 363.7367 - mae: 14.9411\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 365.1338 - mae: 14.9544\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 365.1956 - mae: 14.9400\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 362.3123 - mae: 14.8947\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 353.4688 - mae: 14.6867\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 358.0659 - mae: 14.7955\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 353.3144 - mae: 14.7516\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 353.9117 - mae: 14.7165\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 353.9445 - mae: 14.7037\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 351.7296 - mae: 14.7228\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 347.4351 - mae: 14.5806\n",
            "82/82 [==============================] - 1s 4ms/step\n",
            "Kappa Score: 0.5576164838750768\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    \n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    \n",
        "    sentences = []\n",
        "    \n",
        "    for essay in train_essays:\n",
        "        sentences += essays_to_sentences(essay, remove_stopwords = True)\n",
        "\n",
        "    num_features = 200 \n",
        "\n",
        "    model = embedding_dict\n",
        "\n",
        "    clean_train_essays = []\n",
        "    for essay_v in train_essays:\n",
        "        clean_train_essays.append(essays_to_wordlist(essay_v, remove_stopwords=True))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "    \n",
        "    clean_test_essays = []\n",
        "    for essay_v in test_essays:\n",
        "        clean_test_essays.append(essays_to_wordlist( essay_v, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    \n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = getmodel()\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "\n",
        "    if count == 5:\n",
        "         lstm_model.save('./content/final_lstm.h5')\n",
        "\n",
        "    y_pred = np.round(y_pred)\n",
        "    \n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x20TL4CA7Auf",
        "outputId": "1697026e-0d43-4f0b-dbcd-83ab435aba74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.6319\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \", np.around(np.array(results).mean(),decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SXr1zhQ7MqK",
        "outputId": "7bbd387b-604e-4726-a183-09ad27757769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[80.]]\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "contentBad = \"\"\"\n",
        "        In “Let there be dark,” Paul Bogard talks about the importance of darkness.\n",
        "Darkness is essential to humans. Bogard states, “Our bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of “short sleep” is “long light.” Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isn’t a place for this much artificial light in our lives.” (Bogard 2). Here, Bogard talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy.\n",
        "Animals also need darkness. Bogard states, “The rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well known—the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggs—and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the world’s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earth’s ecology would collapse...” (Bogard 2). Here Bogard explains that animals, too, need darkness to survive.\n",
        "    \"\"\" \n",
        "\n",
        "content = contentBad\n",
        "    \n",
        "if len(content) > 20:\n",
        "    num_features = 200\n",
        "    clean_test_essays = []\n",
        "    clean_test_essays.append(essays_to_wordlist( content, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "\n",
        "    preds = lstm_model.predict(testDataVecs)\n",
        "\n",
        "    if math.isnan(preds):\n",
        "        preds = 0\n",
        "    else:\n",
        "      preds = np.round(preds)\n",
        "\n",
        "    if preds < 0:\n",
        "        preds = 0\n",
        "else:\n",
        "    preds = 0\n",
        "    \n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nBivnTD-8MA6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(lstm_model, open('model_fix.pkl','wb'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4 (tags/v3.9.4:1f2e308, Apr  4 2021, 13:27:16) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c25269a4018224bb4e3cb6b79397037e31419b0dedc1b97e47175df2e08dbf7b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
