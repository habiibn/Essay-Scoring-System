{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SUjaSrAtryJ",
        "outputId": "dc026a82-1b00-4994-ced4-9c308781fde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n"
          ]
        }
      ],
      "source": [
        "! pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Sv17hzafuIc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR = \"../content/\"\n",
        "GLOVE_DIR = './glove.6B/'\n",
        "SAVE_DIR = './'"
      ],
      "metadata": {
        "id": "8d9S-4JJuV-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
        "y = X['domain1_score']\n",
        "X = X.dropna(axis=1)\n",
        "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EirNAdNduhud",
        "outputId": "08a84bb8-50fe-4f61-b166-34c9fbfea710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  Dear local newspaper, I think effects computer...   \n",
              "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "...         ...        ...                                                ...   \n",
              "12971     21626          8   In most stories mothers and daughters are eit...   \n",
              "12972     21628          8   I never understood the meaning laughter is th...   \n",
              "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "12974     21630          8                                 Trippin' on fen...   \n",
              "12975     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "       domain1_score  \n",
              "0                  8  \n",
              "1                  9  \n",
              "2                  7  \n",
              "3                 10  \n",
              "4                  8  \n",
              "...              ...  \n",
              "12971             35  \n",
              "12972             32  \n",
              "12973             40  \n",
              "12974             40  \n",
              "12975             40  \n",
              "\n",
              "[12976 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12971</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12976 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eeb20d02-b214-4c3e-ab7f-6e595bbdab4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_scores = np.array([-1, 2, 1, 0, 0, 0, 0, 0, 0])\n",
        "max_scores = np.array([-1, 12, 6, 3, 3, 4, 4, 30, 60])"
      ],
      "metadata": {
        "id": "ym2cYTOovKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_min = min_scores[X['essay_set']]\n",
        "old_max = max_scores[X['essay_set']]\n",
        "old_range = old_max - old_min\n",
        "new_min = 0\n",
        "new_max = 100\n",
        "new_range = (new_max - new_min)  \n",
        "X['score'] = (((X['domain1_score'] - old_min) * new_range) / old_range) + new_min\n",
        "\n",
        "y = np.round(X['score'])\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oK7QoHjQvNOI",
        "outputId": "6dc62906-1287-4c68-baed-a8e8a919234d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  Dear local newspaper, I think effects computer...   \n",
              "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "...         ...        ...                                                ...   \n",
              "12971     21626          8   In most stories mothers and daughters are eit...   \n",
              "12972     21628          8   I never understood the meaning laughter is th...   \n",
              "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "12974     21630          8                                 Trippin' on fen...   \n",
              "12975     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "       domain1_score      score  \n",
              "0                  8  60.000000  \n",
              "1                  9  70.000000  \n",
              "2                  7  50.000000  \n",
              "3                 10  80.000000  \n",
              "4                  8  60.000000  \n",
              "...              ...        ...  \n",
              "12971             35  58.333333  \n",
              "12972             32  53.333333  \n",
              "12973             40  66.666667  \n",
              "12974             40  66.666667  \n",
              "12975             40  66.666667  \n",
              "\n",
              "[12976 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e083014-e087-4257-afd7-750367db839c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12971</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>35</td>\n",
              "      <td>58.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>32</td>\n",
              "      <td>53.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12976 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e083014-e087-4257-afd7-750367db839c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e083014-e087-4257-afd7-750367db839c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e083014-e087-4257-afd7-750367db839c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEULgzV_vW1P",
        "outputId": "4bb56f34-c7db-44aa-f635-a4b94dd88c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        60.0\n",
              "1        70.0\n",
              "2        50.0\n",
              "3        80.0\n",
              "4        60.0\n",
              "         ... \n",
              "12971    58.0\n",
              "12972    53.0\n",
              "12973    67.0\n",
              "12974    67.0\n",
              "12975    67.0\n",
              "Name: score, Length: 12976, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def essays_to_wordlist(essay_v, remove_stopwords):\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)\n",
        "\n",
        "def essays_to_sentences(essay_v, remove_stopwords):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(essays_to_wordlist(raw_sentence, remove_stopwords))\n",
        "    return sentences\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    # index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec, model[word])       \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "metadata": {
        "id": "wyLR33CYvaBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19dc49d2-b167-401b-b4e9-2ec955d22007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, model_from_config\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def getmodel():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(200, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 200], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8cJNB6j4wIDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "for essay in X['essay']:\n",
        "    corpus.append(essays_to_wordlist(essay, True))\n",
        "\n",
        "embedding_dict={}\n",
        "with open('/content/glove.6B.200d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word] = vectors"
      ],
      "metadata": {
        "id": "e-ntpI7Ywbz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    \n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    \n",
        "    sentences = []\n",
        "    \n",
        "    for essay in train_essays:\n",
        "        sentences += essays_to_sentences(essay, remove_stopwords = True)\n",
        "\n",
        "    num_features = 200 \n",
        "\n",
        "    model = embedding_dict\n",
        "\n",
        "    clean_train_essays = []\n",
        "    for essay_v in train_essays:\n",
        "        clean_train_essays.append(essays_to_wordlist(essay_v, remove_stopwords=True))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "    \n",
        "    clean_test_essays = []\n",
        "    for essay_v in test_essays:\n",
        "        clean_test_essays.append(essays_to_wordlist( essay_v, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    \n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = getmodel()\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "\n",
        "    if count == 5:\n",
        "         lstm_model.save('./content/final_lstm.h5')\n",
        "\n",
        "    y_pred = np.round(y_pred)\n",
        "    \n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuAW1_J522DL",
        "outputId": "fdef42f9-bc5c-4376-e329-6e18aa68fc88"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 10s 21ms/step - loss: 2672.6807 - mae: 46.6787\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1929.2158 - mae: 38.4824\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1415.7772 - mae: 31.8554\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1035.6649 - mae: 26.5177\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 4s 27ms/step - loss: 773.3890 - mae: 22.6583\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 4s 24ms/step - loss: 639.0764 - mae: 20.3728\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 606.1488 - mae: 19.6495\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 591.7869 - mae: 19.3756\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 541.6224 - mae: 18.4797\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 518.5538 - mae: 17.9659\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 502.8181 - mae: 17.6346\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 491.8281 - mae: 17.4876\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 480.3748 - mae: 17.2187\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 472.2377 - mae: 17.0417\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 462.8556 - mae: 16.8700\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 451.9373 - mae: 16.7328\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 447.5579 - mae: 16.6527\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 441.8518 - mae: 16.4716\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 440.0437 - mae: 16.4464\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.3495 - mae: 16.4200\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 423.5803 - mae: 16.0630\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 428.9897 - mae: 16.2307\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 428.5183 - mae: 16.1881\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 413.8267 - mae: 15.9080\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 415.8214 - mae: 15.9099\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 408.7957 - mae: 15.8573\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 404.0211 - mae: 15.7090\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 401.1947 - mae: 15.6329\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 398.3006 - mae: 15.5987\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 395.1987 - mae: 15.5213\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 388.0929 - mae: 15.3795\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 388.3135 - mae: 15.4429\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 384.1538 - mae: 15.3175\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 382.8714 - mae: 15.3271\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 378.5131 - mae: 15.2597\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 373.2366 - mae: 15.1232\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 373.8669 - mae: 15.1247\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 378.3767 - mae: 15.2157\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.2249 - mae: 14.9876\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 366.6355 - mae: 14.9546\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 370.9138 - mae: 15.1037\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 365.9333 - mae: 15.0548\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 361.1456 - mae: 14.9328\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 359.6897 - mae: 14.8688\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 18ms/step - loss: 358.3121 - mae: 14.8467\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 357.7191 - mae: 14.8781\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 356.9964 - mae: 14.7814\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 359.3987 - mae: 14.8715\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 18ms/step - loss: 348.7907 - mae: 14.6272\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 348.3498 - mae: 14.6123\n",
            "82/82 [==============================] - 1s 3ms/step\n",
            "Kappa Score: 0.6611245245641602\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 20ms/step - loss: 2698.8730 - mae: 46.9672\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1947.5006 - mae: 38.7798\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1431.9404 - mae: 32.1041\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1043.6860 - mae: 26.7190\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 787.3843 - mae: 22.9289\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 652.2634 - mae: 20.5457\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 601.3517 - mae: 19.5741\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 578.0474 - mae: 19.1314\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 530.3112 - mae: 18.2105\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 501.6831 - mae: 17.6662\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 492.0779 - mae: 17.4673\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 479.4413 - mae: 17.1848\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 477.8416 - mae: 17.2105\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 464.4239 - mae: 16.9042\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 460.4185 - mae: 16.8625\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 452.2856 - mae: 16.6737\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 449.8396 - mae: 16.5638\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.7646 - mae: 16.4144\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 438.1497 - mae: 16.3954\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 424.9590 - mae: 16.1295\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 424.8655 - mae: 16.1489\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 427.3833 - mae: 16.1670\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 417.8435 - mae: 15.8915\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 416.3316 - mae: 15.9045\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 414.6293 - mae: 15.9366\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 408.2706 - mae: 15.7787\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 406.9213 - mae: 15.7323\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 404.7202 - mae: 15.7332\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 396.6794 - mae: 15.5845\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 393.1125 - mae: 15.5091\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 392.2645 - mae: 15.4906\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 390.8534 - mae: 15.4971\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 385.5491 - mae: 15.3249\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 386.0524 - mae: 15.3170\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 374.8188 - mae: 15.0989\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 377.4406 - mae: 15.2110\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 371.9278 - mae: 15.0794\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 376.5686 - mae: 15.1425\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 371.2856 - mae: 15.0945\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 369.3568 - mae: 15.0270\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.9240 - mae: 14.8958\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 364.7927 - mae: 14.9280\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 365.4706 - mae: 14.9131\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 358.6590 - mae: 14.8016\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 352.0010 - mae: 14.6922\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 350.8768 - mae: 14.6234\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 18ms/step - loss: 353.9607 - mae: 14.7276\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 347.2097 - mae: 14.5257\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 355.3467 - mae: 14.7894\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 349.5078 - mae: 14.5386\n",
            "82/82 [==============================] - 1s 3ms/step\n",
            "Kappa Score: 0.6356328232747533\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 19ms/step - loss: 2762.7317 - mae: 47.6019\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 2006.8718 - mae: 39.4807\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1480.5403 - mae: 32.7429\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1079.7596 - mae: 27.2171\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 4s 25ms/step - loss: 798.4005 - mae: 23.0785\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 646.8834 - mae: 20.5725\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 598.0273 - mae: 19.5360\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 590.4889 - mae: 19.3931\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 542.8903 - mae: 18.4722\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 519.0454 - mae: 17.9645\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 499.5690 - mae: 17.6239\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 489.8231 - mae: 17.3969\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 479.2430 - mae: 17.1474\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 474.7262 - mae: 17.0524\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 468.4376 - mae: 16.9118\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 457.0974 - mae: 16.7196\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 452.2019 - mae: 16.6320\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.6208 - mae: 16.3973\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 440.8860 - mae: 16.4295\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 437.2573 - mae: 16.4194\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 430.7420 - mae: 16.2176\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 426.6248 - mae: 16.1316\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 425.2744 - mae: 16.0876\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 418.0862 - mae: 16.0618\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 419.9966 - mae: 15.9637\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 420.1334 - mae: 16.0276\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 410.6443 - mae: 15.7987\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 401.6038 - mae: 15.6609\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 409.0462 - mae: 15.7646\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 404.6292 - mae: 15.7128\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 394.7194 - mae: 15.4799\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 392.8404 - mae: 15.4718\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 388.6353 - mae: 15.4493\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 379.2338 - mae: 15.1835\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 375.3712 - mae: 15.1098\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 375.4501 - mae: 15.1530\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.9607 - mae: 15.0030\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 375.8416 - mae: 15.1274\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 373.0954 - mae: 15.0722\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 373.4862 - mae: 15.0768\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 362.0414 - mae: 14.8420\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 366.0002 - mae: 14.9371\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 367.2393 - mae: 14.9680\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 359.3964 - mae: 14.7862\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 356.8734 - mae: 14.7637\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 357.4982 - mae: 14.7835\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 360.8893 - mae: 14.8468\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 353.1685 - mae: 14.6434\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 349.8675 - mae: 14.6074\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 339.1474 - mae: 14.4373\n",
            "82/82 [==============================] - 1s 3ms/step\n",
            "Kappa Score: 0.6527565637462656\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 21ms/step - loss: 2671.7153 - mae: 46.6890\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1931.3606 - mae: 38.5507\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1423.0897 - mae: 31.9175\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1032.5123 - mae: 26.5156\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 3s 20ms/step - loss: 775.5212 - mae: 22.7077\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 638.3588 - mae: 20.4170\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 605.1861 - mae: 19.6494\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 587.9741 - mae: 19.3182\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 546.6511 - mae: 18.5412\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 513.2340 - mae: 17.8956\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 503.7606 - mae: 17.6556\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 488.4251 - mae: 17.4054\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 488.1822 - mae: 17.3647\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 474.8081 - mae: 17.1455\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 469.1220 - mae: 17.0472\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 457.7892 - mae: 16.8341\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 5s 28ms/step - loss: 457.9835 - mae: 16.7889\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 446.8854 - mae: 16.6213\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 439.2736 - mae: 16.4325\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 4s 23ms/step - loss: 435.1624 - mae: 16.3760\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 426.7927 - mae: 16.1613\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 426.3866 - mae: 16.1461\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 422.2325 - mae: 16.0835\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 420.3429 - mae: 15.9943\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 414.3321 - mae: 15.8362\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 409.6817 - mae: 15.8707\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 413.5793 - mae: 15.8460\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 402.1431 - mae: 15.7092\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 401.2199 - mae: 15.5848\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 394.8443 - mae: 15.4885\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 391.3001 - mae: 15.5313\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 389.7347 - mae: 15.4924\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 384.1045 - mae: 15.3406\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 380.1281 - mae: 15.1921\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 385.7139 - mae: 15.2668\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 372.3704 - mae: 15.0881\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 379.3423 - mae: 15.1937\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 371.9112 - mae: 15.0840\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 373.6100 - mae: 15.1412\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 372.1598 - mae: 15.0150\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 362.9885 - mae: 14.9172\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 364.5545 - mae: 14.9649\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 366.6730 - mae: 14.9251\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 364.5608 - mae: 14.9267\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 353.0946 - mae: 14.6589\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 354.0661 - mae: 14.6919\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 348.2056 - mae: 14.6376\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 356.4151 - mae: 14.7808\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 357.7351 - mae: 14.6854\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 348.2468 - mae: 14.6198\n",
            "82/82 [==============================] - 1s 4ms/step\n",
            "Kappa Score: 0.6522686709462799\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 9s 21ms/step - loss: 2707.2300 - mae: 47.0729\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 1966.4402 - mae: 38.9944\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1444.7643 - mae: 32.2978\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 1054.2739 - mae: 26.8590\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 785.2654 - mae: 22.8549\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 643.4830 - mae: 20.5031\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 606.4999 - mae: 19.6621\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 601.8312 - mae: 19.5152\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 578.7626 - mae: 19.1554\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 520.3866 - mae: 18.0215\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 504.6905 - mae: 17.7269\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 492.5694 - mae: 17.4091\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 483.2235 - mae: 17.2588\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 472.2931 - mae: 17.0683\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 459.6768 - mae: 16.8712\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 461.2121 - mae: 16.8866\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 442.1555 - mae: 16.5228\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 4s 23ms/step - loss: 447.5595 - mae: 16.6145\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 436.4877 - mae: 16.3366\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 434.2061 - mae: 16.3242\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 429.8312 - mae: 16.2778\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 427.3695 - mae: 16.1927\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 422.2131 - mae: 16.0730\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 4s 28ms/step - loss: 413.4859 - mae: 15.9206\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 411.7534 - mae: 15.9126\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 410.3990 - mae: 15.8260\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 408.9684 - mae: 15.8136\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 401.2662 - mae: 15.6811\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 399.6621 - mae: 15.5958\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 392.6707 - mae: 15.4854\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 385.6630 - mae: 15.3763\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 381.5781 - mae: 15.2885\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 382.4182 - mae: 15.3359\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 378.8458 - mae: 15.2225\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 377.9791 - mae: 15.2118\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 379.2138 - mae: 15.1951\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 371.5058 - mae: 15.0909\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 371.7595 - mae: 15.0664\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 373.4474 - mae: 15.1056\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 4s 21ms/step - loss: 363.7367 - mae: 14.9411\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 365.1338 - mae: 14.9544\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 365.1956 - mae: 14.9400\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 362.3123 - mae: 14.8947\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 353.4688 - mae: 14.6867\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 358.0659 - mae: 14.7955\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 353.3144 - mae: 14.7516\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 353.9117 - mae: 14.7165\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 353.9445 - mae: 14.7037\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 351.7296 - mae: 14.7228\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 4s 22ms/step - loss: 347.4351 - mae: 14.5806\n",
            "82/82 [==============================] - 1s 4ms/step\n",
            "Kappa Score: 0.5576164838750768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \", np.around(np.array(results).mean(),decimals=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x20TL4CA7Auf",
        "outputId": "1697026e-0d43-4f0b-dbcd-83ab435aba74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.6319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "contentBad = \"\"\"\n",
        "        In “Let there be dark,” Paul Bogard talks about the importance of darkness.\n",
        "Darkness is essential to humans. Bogard states, “Our bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of “short sleep” is “long light.” Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isn’t a place for this much artificial light in our lives.” (Bogard 2). Here, Bogard talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy.\n",
        "Animals also need darkness. Bogard states, “The rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well known—the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggs—and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the world’s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earth’s ecology would collapse...” (Bogard 2). Here Bogard explains that animals, too, need darkness to survive.\n",
        "    \"\"\" \n",
        "\n",
        "content = contentBad\n",
        "    \n",
        "if len(content) > 20:\n",
        "    num_features = 200\n",
        "    clean_test_essays = []\n",
        "    clean_test_essays.append(essays_to_wordlist( content, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "\n",
        "    preds = lstm_model.predict(testDataVecs)\n",
        "\n",
        "    if math.isnan(preds):\n",
        "        preds = 0\n",
        "    else:\n",
        "      preds = np.round(preds)\n",
        "\n",
        "    if preds < 0:\n",
        "        preds = 0\n",
        "else:\n",
        "    preds = 0\n",
        "    \n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SXr1zhQ7MqK",
        "outputId": "7bbd387b-604e-4726-a183-09ad27757769"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[80.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(lstm_model, open('model_fix.pkl','wb'))\n"
      ],
      "metadata": {
        "id": "nBivnTD-8MA6"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}